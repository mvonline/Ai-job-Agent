LLM_PROVIDER=ollama
MODEL_NAME=smollm:135m # Ultra-light/fast (135M) or llama3.2 (3B)
MAX_JOBS=40 # Minimum number of jobs to search for

# --- OLLAMA CONFIG (Local) ---
OLLAMA_BASE_URL=http://localhost:11434

# --- GEMINI CONFIG (Online) ---
GEMINI_API_KEY=your_gemini_api_key_here
# Some versions of libraries prefer GOOGLE_API_KEY
GOOGLE_API_KEY=your_gemini_api_key_here
# Sample models: gemini-2.0-flash, gemini-1.5-flash
# MODEL_NAME=gemini-2.0-flash

# --- OPENAI CONFIG (Online) ---
OPENAI_API_KEY=your_openai_api_key_here
# Sample models: gpt-4o, gpt-4-turbo
# MODEL_NAME=gpt-4o
